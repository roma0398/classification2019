{
 "cells": [
  {
   "cell_type": "code",
   "execution_count": 1,
   "metadata": {},
   "outputs": [],
   "source": [
    "import zipfile\n",
    "import codecs\n",
    "\n",
    "import pymorphy2\n",
    "import re\n",
    "import tqdm"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 2,
   "metadata": {},
   "outputs": [],
   "source": [
    "def read_texts(fn='data/texts.zip'):\n",
    "    with zipfile.ZipFile(fn) as zf:\n",
    "        with zf.open('texts.txt') as f:\n",
    "            yield from codecs.iterdecode(f, 'utf-8')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 3,
   "metadata": {},
   "outputs": [],
   "source": [
    "class Parser:\n",
    "    def __init__(self):        \n",
    "        self.pm = pymorphy2.MorphAnalyzer()\n",
    "        self.r = re.compile(r'\\W+')\n",
    "    \n",
    "    def parse(self, text):\n",
    "        words = (word for word in self.r.split(text) if len(word) > 0)\n",
    "        norm_form = (self.pm.normal_forms(word)[0] for word in words)\n",
    "    \n",
    "        return list(words)"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 4,
   "metadata": {},
   "outputs": [],
   "source": [
    "from collections import defaultdict, Counter\n",
    "\n",
    "class Doc:\n",
    "    def __init__(self, doc_id, title, text):\n",
    "        self.doc_id = doc_id\n",
    "        self.title = title\n",
    "        self.text = text\n",
    "\n",
    "class Posting:\n",
    "    def __init__(self, doc_id, positions: list):\n",
    "        self.doc_id = doc_id\n",
    "        self.positions = positions\n",
    "        \n",
    "class Indexer:\n",
    "    def __init__(self):\n",
    "        self.inv_index = defaultdict(list)\n",
    "        self.dictionary = Counter()\n",
    "        self.parser = Parser()\n",
    "        self.docs = []\n",
    "    \n",
    "    def index_doc(self, doc: Doc):\n",
    "        doc_index = defaultdict(list)\n",
    "        for pos, word in enumerate(\n",
    "                        self.parser.parse(doc.text)):\n",
    "            doc_index[word].append(pos)\n",
    "            \n",
    "        self.dictionary.update(doc_index.keys())\n",
    "        \n",
    "        # ToDo: fix it to get tf*idf!!!\n",
    "        for word, positions in doc_index.items():\n",
    "            posting = Posting(len(self.docs), positions)\n",
    "            self.inv_index[word].append(posting)   \n",
    "            \n",
    "        self.docs.append(doc)\n",
    "        \n",
    "    def search(self, q, n=10):\n",
    "        q_words = self.parser.parse(q)\n",
    "        scores = defaultdict(lambda: 0.)\n",
    "        \n",
    "        for q_word in q_words:\n",
    "            df = self.dictionary[q_word]\n",
    "            for posting in self.inv_index[q_word]:\n",
    "                doc_id = posting.doc_id\n",
    "                tf = len(posting.positions)\n",
    "                scores[doc_id] += tf / df\n",
    "                \n",
    "        res = sorted(scores.items(), key=lambda x: -x[1])[:n]\n",
    "        return [(self.docs[x], rel) for (x, rel) in res]"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 8,
   "metadata": {},
   "outputs": [
    {
     "data": {
      "application/vnd.jupyter.widget-view+json": {
       "model_id": "3e4c777243b14221abe92ed6ba994014",
       "version_major": 2,
       "version_minor": 0
      },
      "text/plain": [
       "HBox(children=(IntProgress(value=0, max=50), HTML(value='')))"
      ]
     },
     "metadata": {},
     "output_type": "display_data"
    },
    {
     "name": "stdout",
     "output_type": "stream",
     "text": [
      "\n"
     ]
    }
   ],
   "source": [
    "from itertools import islice\n",
    "\n",
    "indexer = Indexer()\n",
    "\n",
    "docs = enumerate(islice(read_texts(), 150))\n",
    "for doc_id, text in tqdm.tqdm_notebook(docs, total=50):\n",
    "    indexer.index_doc(Doc(doc_id, '', text))"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 9,
   "metadata": {},
   "outputs": [],
   "source": [
    "res = indexer.search('браун')"
   ]
  },
  {
   "cell_type": "code",
   "execution_count": 10,
   "metadata": {},
   "outputs": [],
   "source": [
    "for doc, rel in res:\n",
    "    print(rel, '------', doc.text[:50])"
   ]
  }
 ],
 "metadata": {
  "kernelspec": {
   "display_name": "Python 3",
   "language": "python",
   "name": "python3"
  },
  "language_info": {
   "codemirror_mode": {
    "name": "ipython",
    "version": 3
   },
   "file_extension": ".py",
   "mimetype": "text/x-python",
   "name": "python",
   "nbconvert_exporter": "python",
   "pygments_lexer": "ipython3",
   "version": "3.6.8"
  }
 },
 "nbformat": 4,
 "nbformat_minor": 2
}
